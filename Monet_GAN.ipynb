{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# import tensorflow as tf\n# import matplotlib.pyplot as plt\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -q git+https://github.com/tensorflow/examples.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport math\nimport random\nimport re\nimport cv2\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow_examples.models.pix2pix import pix2pix\nimport os\nimport PIL\nimport PIL.Image\n\nimport pathlib","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"photo_dir = '../input/gan-getting-started/photo_jpg/'\nmonet_dir = '../input/gan-getting-started/monet_jpg/'\nmonet_tfrec = '../input/gan-getting-started/monet_tfrec/monet00-60.tfrec'\nBATCH_SIZE=1\nBUFFER_SIZE=1000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_names = tf.io.gfile.glob(r\"../input/gan-getting-started/monet_tfrec/*.tfrec\")\nprint(monet_names)\nphoto_names = tf.io.gfile.glob(r\"../input/gan-getting-started/photo_tfrec/*.tfrec\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_image(img, dim = 256):    \n    img = tf.image.decode_jpeg(img, channels = 3)\n    img = (tf.cast(img, tf.float32)*2 / 255.0) - 1\n    img = tf.reshape(img, [dim, dim, 3])\n    return img\n\ndef read_tfrecord(example):\n    tfrec_format = {\n        'image' : tf.io.FixedLenFeature([], tf.string),\n        'image_name' : tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }   \n    \n    example = tf.io.parse_single_example(example, tfrec_format)\n    image = prepare_image(example['image'])\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(filenames, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_ds = load_dataset(monet_names, labeled=True)\nphoto_ds = load_dataset(photo_names, labeled=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = '../input/gan-getting-started/'\nmonet_path = os.path.join(base_path, 'monet_jpg')\nphoto_path = os.path.join(base_path, 'photo_jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_visualization(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    n=2\n    w = int(n_images ** .5)\n    h = math.ceil(n_images / w)\n    \n    all_names = os.listdir(path)\n    \n    image_names = all_names[:n_images]\n    if is_random:\n        image_names = random.sample(all_names, n_images)\n    \n    for ind, image_name in enumerate(image_names):\n        img = cv2.imread(os.path.join(path, image_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        plt.subplot(h, w, ind +1)\n        plt.imshow(img)\n        plt.axis('off')\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_visualization(monet_path,3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figsize=(16, 16)\nn=3\nplt.figure(plt.figure(figsize=figsize))\nj=0\nfor raw_record in monet_ds.take(3):\n    #print((raw_record))\n    \n    for i in range(n):\n        img=data_augmentation(tf.expand_dims(raw_record, 0))\n        plt.subplot(3, n, j*n+i +1)\n        plt.imshow(img[0]/2+1/2)\n    j+=1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_monet = monet_ds.take(0).shuffle(BUFFER_SIZE).batch(BATCH_SIZE) \ntrain_monet = monet_ds.skip(0).shuffle(BUFFER_SIZE).batch(BATCH_SIZE) \n\ntest_photo = photo_ds.take(0).shuffle(BUFFER_SIZE).batch(BATCH_SIZE,)  \ntrain_photo = photo_ds.skip(0).shuffle(BUFFER_SIZE).batch(BATCH_SIZE) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_monet = train_monet.map(\n  lambda x: (data_augmentation(x, training=True)))\n\ntrain_photo = train_photo.map(\n  lambda x: (data_augmentation(x, training=True)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nfor raw_record in monet_ds.take(2):\n    #print((raw_record).numpy())\n    plt.imshow((raw_record).numpy()+1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_monet = next(iter(train_monet))\nsample_photo = next(iter(train_photo))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUT_CHANNELS = 3\n\ngenerator_monet = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\ngenerator_photo = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n\ndiscriminator_monet = pix2pix.discriminator(norm_type='instancenorm', target=False)\ndiscriminator_photo = pix2pix.discriminator(norm_type='instancenorm', target=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_photo = generator_monet(sample_monet)\nto_monet = generator_photo(sample_photo)\nplt.figure(figsize=(8, 8))\ncontrast = 1\n\nimgs = [sample_monet, to_photo, sample_photo, to_monet]\ntitle = ['MONET', 'TO PHOTO', 'PHOTO', 'TO MONET']\n\nfor i in range(len(imgs)):\n    plt.subplot(2, 2, i+1)\n    plt.title(title[i])\n    if i % 2 == 0:\n        plt.imshow(imgs[i][0]/2 + 1/2)\n    else:\n        plt.imshow(imgs[i][0]/2  * contrast + 1/2)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 8))\n\nplt.subplot(121)\nplt.title('Is a real monet?')\nplt.imshow(discriminator_monet(sample_monet)[0, ..., -1], cmap='RdBu_r')\n\nplt.subplot(122)\nplt.title('Is a real photo?')\nplt.imshow(discriminator_photo(sample_photo)[0, ..., -1], cmap='RdBu_r')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LAMBDA = 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real, generated):\n    real_loss = loss_obj(tf.ones_like(real), real)\n    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n    total_disc_loss = real_loss + generated_loss\n    return total_disc_loss * 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_loss(generated):\n    return loss_obj(tf.ones_like(generated), generated)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_cycle_loss(real_image, cycled_image):\n    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n    return LAMBDA * loss1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_loss(real_image, same_image):\n    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n    return LAMBDA * 0.5 * loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_monet_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ngenerator_photo_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n\ndiscriminator_monet_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ndiscriminator_photo_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"./\"\n\nckpt = tf.train.Checkpoint(generator_monet=generator_monet,\n                           generator_photo=generator_photo,\n                           discriminator_monet=discriminator_monet,\n                           discriminator_photo=discriminator_photo,\n                           generator_monet_optimizer=generator_monet_optimizer,\n                           generator_photo_optimizer=generator_photo_optimizer,\n                           discriminator_monet_optimizer=discriminator_monet_optimizer,\n                           discriminator_photo_optimizer=discriminator_photo_optimizer)\n\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n\n# if a checkpoint exists, restore the latest checkpoint.\nif ckpt_manager.latest_checkpoint:\n    ckpt.restore(ckpt_manager.latest_checkpoint)\n    print ('Latest checkpoint restored!!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 200\ndef generate_images(model, test_input):\n    prediction = model(test_input)\n    plt.figure(figsize=(12, 12))\n    display_list = [test_input[0], prediction[0]]\n    title = ['Input Image', 'Predicted Image']\n    \n    for i in range(2):\n        plt.subplot(1, 2, i+1)\n        plt.title(title[i])\n    # getting the pixel values between [0, 1] to plot it.\n        plt.imshow(display_list[i] * 1/2 + 1/2)\n        plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(real_photo, real_monet):\n    with tf.GradientTape(persistent=True) as tape:\n        fake_monet = generator_monet(real_photo, training=True)\n        cycled_photo = generator_photo(fake_monet, training=True)\n\n        fake_photo = generator_photo(real_monet, training=True)\n        cycled_monet = generator_monet(fake_photo, training=True)\n\n        # same_x and same_y are used for identity loss.\n        same_photo = generator_photo(real_photo, training=True)\n        same_monet = generator_monet(real_monet, training=True)\n\n        disc_real_photo = discriminator_photo(real_photo, training=True)\n        disc_real_monet = discriminator_monet(real_monet, training=True)\n\n        disc_fake_photo = discriminator_photo(fake_photo, training=True)\n        disc_fake_monet = discriminator_monet(fake_monet, training=True)\n\n        # calculate the loss\n        gen_monet_loss = generator_loss(disc_fake_monet)\n        gen_photo_loss = generator_loss(disc_fake_photo)\n\n        total_cycle_loss = calc_cycle_loss(real_photo, cycled_photo) + calc_cycle_loss(real_monet, cycled_monet)\n\n        # Total generator loss = adversarial loss + cycle loss\n        total_gen_monet_loss = gen_monet_loss + total_cycle_loss + identity_loss(real_monet, same_monet)\n        total_gen_photo_loss = gen_photo_loss + total_cycle_loss + identity_loss(real_photo, same_photo)\n\n        disc_photo_loss = discriminator_loss(disc_real_photo, disc_fake_photo)\n        disc_monet_loss = discriminator_loss(disc_real_monet, disc_fake_monet)\n\n  # Calculate the gradients for generator and discriminator\n    generator_monet_gradients = tape.gradient(total_gen_monet_loss, \n                                        generator_monet.trainable_variables)\n    generator_photo_gradients = tape.gradient(total_gen_photo_loss, \n                                        generator_photo.trainable_variables)\n\n    discriminator_photo_gradients = tape.gradient(disc_photo_loss, \n                                            discriminator_photo.trainable_variables)\n    discriminator_monet_gradients = tape.gradient(disc_monet_loss, \n                                            discriminator_monet.trainable_variables)\n\n    # Apply the gradients to the optimizer\n    generator_monet_optimizer.apply_gradients(zip(generator_monet_gradients, \n                                            generator_monet.trainable_variables))\n\n    generator_photo_optimizer.apply_gradients(zip(generator_photo_gradients, \n                                            generator_photo.trainable_variables))\n\n    discriminator_photo_optimizer.apply_gradients(zip(discriminator_photo_gradients,\n                                                discriminator_photo.trainable_variables))\n\n    discriminator_monet_optimizer.apply_gradients(zip(discriminator_monet_gradients,\n                                                discriminator_monet.trainable_variables))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfor epoch in range(EPOCHS):\n    start = time.time()\n\n    n = 0\n    for image_photo, image_monet in tf.data.Dataset.zip((train_photo, train_monet)):\n        train_step(image_photo, image_monet)\n        if n % 10 == 0:\n            print ('.', end='')\n        n += 1\n\n    #clear_output(wait=True)\n  # Using a consistent image (sample_horse) so that the progress of the model\n  # is clearly visible.\n    generate_images(generator_monet, sample_photo)\n\n    if (epoch + 1) % 5 == 0:\n        ckpt_save_path = ckpt_manager.save()\n        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n                                                             ckpt_save_path))\n\n    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n                                                      time.time()-start))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Run the trained model on the test dataset\n# for inp in test_photo.take(20):\n#     generate_images(generator_monet, inp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the trained model on the test dataset\nfor inp in train_photo.take(20):\n    generate_images(generator_monet, inp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for inp in test_monet.take(5):\n#     generate_images(generator_photo, inp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for inp in train_monet.take(5):\n#     generate_images(generator_photo, inp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for inp in test_photo.take(5):\n#     generate_images(generator_photo, inp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for inp in train_photo.take(5):\n#     generate_images(generator_photo, inp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for inp in test_monet.take(5):\n#     generate_images(generator_monet, inp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for inp in train_monet.take(5):\n#     generate_images(generator_monet, inp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.remove(\"./submission\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"../images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=1\nsavepath=\"../images/\"\nfor image in photo_ds.take(7000):\n    image=generator_monet(tf.expand_dims(image, 0))\n    image=(image[0] * 1/2 + 1/2)*255\n    img = PIL.Image.fromarray(image.numpy().astype('uint8'), 'RGB')\n    name=savepath+'image_'+str(n)+'.jpg'\n    img.save(name)\n    if (n%300==0):\n        print(n)\n    n+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('/kaggle/working/images/', 'zip', '../images')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n=1\n# img = PIL.Image.fromarray(data, 'RGB')\n# name='image'+str(n)+'.jpg',\n# img.save(name)\n# img.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}